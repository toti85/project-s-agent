"""
Project-S Intelligent Workflow System
------------------------------------
A komplex, t√∂bbl√©pcs≈ës AI-vez√©relt workflow-k kezel√©s√©re szolg√°l√≥ rendszer.
T√°mogatja az intelligens eszk√∂zv√°laszt√°st, d√∂nt√©shozatalt √©s √°llapotk√∂vet√©st.

Ez a modul a Project-S eszk√∂zrendszerre √©p√ºl, √©s a LangGraph-ot haszn√°lja
a workflow-k struktur√°l√°s√°ra √©s v√©grehajt√°s√°ra.

F≈ëbb komponensek:
- SmartToolOrchestrator: Eszk√∂z√∂k intelligens kiv√°laszt√°sa √©s l√°ncol√°sa
- WorkflowDecisionEngine: K√∂ztes eredm√©nyek elemz√©se √©s k√∂vetkez≈ë l√©p√©sek meghat√°roz√°sa 
- WorkflowContextManager: √Ållapotk√∂vet√©s √©s kontextus kezel√©s
- EnhancedLangGraphIntegration: LangGraph munkafolyamatok kiterjesztett integr√°ci√≥ja
"""

import asyncio
import logging
import os
import sys
import json
import time
import uuid
import traceback
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional, Union, Callable, Tuple, TypedDict, cast

# Napl√≥z√°s be√°ll√≠t√°sa
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger("intelligent_workflow")

# Adjuk hozz√° a projekt gy√∂k√©rk√∂nyvt√°r√°t a keres√©si √∫tvonalhoz
project_root = Path(__file__).parent
if str(project_root) not in sys.path:
    sys.path.append(str(project_root))

# Project-S import√°l√°sok
try:
    from tools import register_all_tools
    from tools.file_tools import FileWriteTool, FileReadTool
    from tools.web_tools import WebPageFetchTool
    from tools.tool_interface import BaseTool
    from tools.tool_registry import tool_registry
    logger.info("‚úÖ Project-S eszk√∂z√∂k import√°l√°sa sikeres")
except ImportError as e:
    logger.error(f"‚ùå Hiba a Project-S eszk√∂z√∂k import√°l√°sakor: {e}")
    sys.exit(1)

# LangGraph import√°l√°sok
try:
    from langgraph.graph import StateGraph
    from langgraph.prebuilt import ToolNode
    from langgraph.graph.message import add_messages
    logger.info("‚úÖ LangGraph import√°l√°sa sikeres")
except ImportError as e:
    logger.error(f"‚ùå Hiba a LangGraph import√°l√°sakor: {e}")
    logger.error("Futtassa a 'pip install langgraph' parancsot a hi√°nyz√≥ k√∂nyvt√°r telep√≠t√©s√©hez.")
    sys.exit(1)

class WorkflowState(TypedDict, total=False):
    """
    Workflow √°llapot a munkafolyamatok k√∂vet√©s√©hez.
    """
    messages: List[Dict[str, Any]]
    tool_results: Dict[str, Any]
    errors: List[Dict[str, Any]]
    
    # Workflow-specifikus mez≈ëk
    workflow_id: str
    start_time: str
    current_step: str
    completed_steps: List[str]
    input_data: Dict[str, Any]
    intermediate_results: Dict[str, Any]
    output_data: Dict[str, Any]
    metadata: Dict[str, Any]

class SmartToolOrchestrator:
    """
    Intelligens eszk√∂zkezel≈ë az optim√°lis eszk√∂z√∂k kiv√°laszt√°s√°hoz √©s
    v√©grehajt√°si l√°ncok l√©trehoz√°s√°hoz.
    """
    
    def __init__(self):
        """
        Inicializ√°lja az intelligens eszk√∂zk√©szletet.
        """
        self.available_tools: Dict[str, BaseTool] = {}
        self.tool_capabilities: Dict[str, Dict[str, Any]] = {}
        self.execution_history: List[Dict[str, Any]] = []
    
    async def register_available_tools(self):
        """
        Regisztr√°lja az el√©rhet≈ë eszk√∂z√∂ket a rendszerb≈ël.
        """
        logger.info("üîç El√©rhet≈ë eszk√∂z√∂k regisztr√°l√°sa...")
        
        # Az √∂sszes eszk√∂z regisztr√°l√°sa a registry-b≈ël
        try:
            await register_all_tools()
            
            # Az el√©rhet≈ë eszk√∂z√∂k lek√©r√©se - k√∂zvetlen hozz√°f√©r√©s a tools dictionary-hez
            self.available_tools = tool_registry.tools
            
            # Eszk√∂z k√©pess√©geinek felt√©rk√©pez√©se
            for name, tool in self.available_tools.items():
                self.tool_capabilities[name] = {
                    "name": name,
                    "description": tool.__doc__ or "",
                    "parameters": getattr(tool, "parameters", {}),
                    "category": self._determine_tool_category(tool),
                    "async": asyncio.iscoroutinefunction(tool.execute)
                }
                
            logger.info(f"‚úÖ {len(self.available_tools)} eszk√∂z sikeresen regisztr√°lva")
            
        except Exception as e:
            logger.error(f"‚ùå Hiba az eszk√∂z√∂k regisztr√°ci√≥jakor: {str(e)}")
            raise
    
    def _determine_tool_category(self, tool: BaseTool) -> str:
        """
        Meghat√°rozza egy eszk√∂z kateg√≥ri√°j√°t a neve √©s funkci√≥i alapj√°n.
        """
        name = tool.__class__.__name__.lower()
        
        if "file" in name:
            return "file_operation"
        elif "web" in name:
            return "web_operation"
        elif "code" in name:
            return "code_operation"
        elif "system" in name:
            return "system_operation"
        else:
            return "general"
    
    async def select_best_tool(self, task_description: str, context: Dict[str, Any]) -> Tuple[str, BaseTool]:
        """
        Kiv√°lasztja a legjobb eszk√∂zt egy feladat v√©grehajt√°s√°hoz.
        """
        logger.info(f"üîç Eszk√∂z kiv√°laszt√°sa a feladathoz: {task_description}")
        
        # Egyszer≈± eszk√∂zv√°laszt√°si logika - k√©s≈ëbb AI-alap√∫ lehet
        task_lower = task_description.lower()
        
        # Web m≈±velet felismer√©se
        if any(kw in task_lower for kw in ["web", "url", "http", "fetch", "download"]):
            tool_name = next(
                (name for name, cap in self.tool_capabilities.items() 
                if cap["category"] == "web_operation"),
                None
            )
            if tool_name:
                logger.info(f"‚úÖ Kiv√°lasztott eszk√∂z: {tool_name} (web operation)")
                return tool_name, self.available_tools[tool_name]
        
        # F√°jlm≈±veletek felismer√©se
        if any(kw in task_lower for kw in ["file", "save", "write", "read", "load"]):
            # K√ºl√∂nb√∂ztess√ºnk meg olvas√°si √©s √≠r√°si m≈±veleteket
            if any(kw in task_lower for kw in ["save", "write", "create"]):
                tool_candidates = [
                    name for name, cap in self.tool_capabilities.items()
                    if cap["category"] == "file_operation" and "write" in name.lower()
                ]
            else:
                tool_candidates = [
                    name for name, cap in self.tool_capabilities.items()
                    if cap["category"] == "file_operation" and "read" in name.lower()
                ]
                
            if tool_candidates:
                tool_name = tool_candidates[0]
                logger.info(f"‚úÖ Kiv√°lasztott eszk√∂z: {tool_name} (file operation)")
                return tool_name, self.available_tools[tool_name]
        
        # Alap√©rtelmezett eszk√∂z vagy hiba
        if not self.available_tools:
            raise ValueError("Nincsenek el√©rhet≈ë eszk√∂z√∂k a rendszerben")
        
        # V√°lasszuk ki az els≈ë el√©rhet≈ë eszk√∂zt
        default_tool_name = next(iter(self.available_tools.keys()))
        default_tool = self.available_tools[default_tool_name]
        logger.warning(f"‚ö†Ô∏è Nem siker√ºlt specifikus eszk√∂zt tal√°lni. Alap√©rtelmezett eszk√∂z haszn√°lata: {default_tool_name}")
        
        return default_tool_name, default_tool
    
    async def execute_tool_chain(self, tool_sequence: List[Tuple[str, Dict[str, Any]]], 
                              initial_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        V√©grehajt egy eszk√∂zl√°ncot, ahol az el≈ëz≈ë eszk√∂z kimenete a k√∂vetkez≈ë bemenete lesz.
        """
        logger.info(f"üîÑ Eszk√∂zl√°nc v√©grehajt√°sa ({len(tool_sequence)} l√©p√©s)...")
        
        current_data = initial_data.copy()
        results = {}
        
        for i, (tool_name, params) in enumerate(tool_sequence):
            try:
                # Ellen≈ërizz√ºk, hogy az eszk√∂z l√©tezik-e
                if tool_name not in self.available_tools:
                    raise ValueError(f"Az eszk√∂z nem l√©tezik: {tool_name}")
                
                tool = self.available_tools[tool_name]
                
                logger.info(f"‚öôÔ∏è V√©grehajt√°s: {tool_name} (l√©p√©s {i+1}/{len(tool_sequence)})")
                
                # Param√©terek el≈ëk√©sz√≠t√©se a kontextus alapj√°n
                prepared_params = self._prepare_parameters(tool, params, current_data)
                
                # Eszk√∂z v√©grehajt√°sa
                start_time = time.time()
                result = await tool.execute(**prepared_params)
                execution_time = time.time() - start_time
                
                # Eredm√©ny ment√©se
                results[tool_name] = result
                
                # √Ållapot friss√≠t√©se a k√∂vetkez≈ë eszk√∂znek
                current_data.update(self._extract_relevant_output(tool_name, result))
                
                # V√©grehajt√°si napl√≥
                self.execution_history.append({
                    "tool": tool_name,
                    "params": params,
                    "execution_time": execution_time,
                    "success": True,
                    "timestamp": datetime.now().isoformat()
                })
                
                logger.info(f"‚úÖ {tool_name} sikeresen v√©grehajtva ({execution_time:.2f}s)")
                
            except Exception as e:
                logger.error(f"‚ùå Hiba a(z) {tool_name} eszk√∂z v√©grehajt√°sakor: {str(e)}")
                
                # Hibanapl√≥
                self.execution_history.append({
                    "tool": tool_name,
                    "params": params,
                    "error": str(e),
                    "success": False,
                    "timestamp": datetime.now().isoformat()
                })
                
                # Pr√≥b√°ljuk meg a hib√°t kezelni
                handled = await self.handle_tool_failures(tool_name, e, current_data)
                if not handled:
                    raise
        
        return {
            "final_result": current_data,
            "individual_results": results,
            "execution_history": self.execution_history
        }
    
    def _prepare_parameters(self, tool: BaseTool, params: Dict[str, Any], 
                          context: Dict[str, Any]) -> Dict[str, Any]:
        """
        El≈ëk√©sz√≠ti a param√©tereket egy eszk√∂z sz√°m√°ra, figyelembe v√©ve a kontextust.
        """
        prepared_params = params.copy()
        
        # Itt lehet implement√°lni speci√°lis param√©terkezel√©st
        # P√©ld√°ul: param√©terek automatikus kit√∂lt√©se a kontextusb√≥l
        
        return prepared_params
    
    def _extract_relevant_output(self, tool_name: str, result: Any) -> Dict[str, Any]:
        """
        Kinyeri a relev√°ns inform√°ci√≥kat egy eszk√∂z kimenet√©b≈ël.
        """
        output = {}
        
        # Alap√©rtelmezett feldolgoz√°s
        if isinstance(result, dict):
            # Ha az eredm√©ny sz√≥t√°r, akkor minden kulcsot √°tvesz√ºnk egy prefixszel
            prefix = f"{tool_name.lower()}_"
            output = {f"{prefix}{key}": value for key, value in result.items()}
        else:
            # Egy√©b esetben az eredm√©nyt k√∂zvetlen√ºl t√°roljuk
            output[tool_name.lower() + "_result"] = result
            
        return output
    
    async def handle_tool_failures(self, failed_tool: str, error: Exception, 
                               context: Dict[str, Any]) -> bool:
        """
        Kezeli az eszk√∂zhib√°kat, √©s megpr√≥b√°l alternat√≠v√°kat tal√°lni.
        """
        logger.warning(f"‚ö†Ô∏è Hibakezel√©s a k√∂vetkez≈ë eszk√∂zh√∂z: {failed_tool}")
        
        # Egyszer≈± hibakezel√©si logika
        tool_category = next(
            (cap["category"] for name, cap in self.tool_capabilities.items() if name == failed_tool),
            None
        )
        
        if not tool_category:
            logger.error(f"‚ùå Nem ismert eszk√∂zkateg√≥ria: {failed_tool}")
            return False
        
        # Alternat√≠v eszk√∂z√∂k keres√©se ugyanabban a kateg√≥ri√°ban
        alternatives = [
            name for name, cap in self.tool_capabilities.items()
            if cap["category"] == tool_category and name != failed_tool
        ]
        
        if alternatives:
            alternative = alternatives[0]
            logger.info(f"üîÑ Alternat√≠v eszk√∂z haszn√°lata: {alternative}")
            
            # Itt lehetne implement√°lni az alternat√≠v eszk√∂z v√©grehajt√°s√°t
            # Ez most egyszer≈±s√≠tve van, csak jelezz√ºk, hogy tal√°ltunk alternat√≠v√°t
            
            return True
        
        logger.error(f"‚ùå Nem tal√°lhat√≥ alternat√≠v eszk√∂z a k√∂vetkez≈ë kateg√≥ri√°ban: {tool_category}")
        return False

class WorkflowDecisionEngine:
    """
    D√∂nt√©si motor az intelligens workflow vez√©rl√©shez.
    Elemzi a k√∂ztes eredm√©nyeket √©s meghat√°rozza a k√∂vetkez≈ë l√©p√©seket.
    """
    
    def __init__(self):
        """
        Inicializ√°lja a d√∂nt√©si motort.
        """
        self.decision_history = []
    
    async def analyze_intermediate_results(self, step_output: Dict[str, Any]) -> Dict[str, Any]:
        """
        Elemzi a munkafolyamat k√∂ztes eredm√©nyeit.
        """
        logger.info("üîç K√∂ztes eredm√©nyek elemz√©se...")
        
        analysis = {
            "has_error": self._check_for_errors(step_output),
            "data_quality": self._assess_data_quality(step_output),
            "content_type": self._determine_content_type(step_output),
            "analysis_timestamp": datetime.now().isoformat()
        }
        
        return analysis
    
    async def decide_next_action(self, current_state: Dict[str, Any], available_tools: List[str]) -> str:
        """
        Eld√∂nti a k√∂vetkez≈ë m≈±veletet az aktu√°lis √°llapot alapj√°n.
        """
        logger.info("ü§î K√∂vetkez≈ë m≈±velet meghat√°roz√°sa...")
        
        # √Ållapot elemz√©se
        has_error = current_state.get("has_error", False)
        current_step = current_state.get("current_step", "")
        content_type = current_state.get("content_type", "unknown")
        
        # D√∂nt√©si logika
        next_action = "default"
        
        if has_error:
            next_action = "error_handling"
        elif content_type == "technical":
            next_action = "deep_analysis"
        elif content_type == "general":
            next_action = "summary_only"
        
        # D√∂nt√©s napl√≥z√°sa
        self.decision_history.append({
            "current_state": current_state,
            "decision": next_action,
            "timestamp": datetime.now().isoformat()
        })
        
        logger.info(f"‚úÖ D√∂nt√©s: {next_action}")
        return next_action
    
    async def evaluate_success_criteria(self, workflow_results: Dict[str, Any]) -> bool:
        """
        √ârt√©keli, hogy a munkafolyamat eredm√©nye megfelel-e a sikerkrit√©riumoknak.
        """
        logger.info("üßê Sikerkrit√©riumok √©rt√©kel√©se...")
        
        # Alapvet≈ë ellen≈ërz√©sek
        required_files = ["raw_content.txt", "analysis_data.json", "executive_summary.md"]
        file_results = workflow_results.get("file_results", {})
        
        # Ellen≈ërizz√ºk, hogy a sz√ºks√©ges f√°jlok l√©trej√∂ttek-e
        files_created = [
            filename for filename, result in file_results.items()
            if result.get("success", False)
        ]
        
        missing_files = [f for f in required_files if not any(f in filename for filename in files_created)]
        
        if missing_files:
            logger.warning(f"‚ö†Ô∏è Hi√°nyz√≥ f√°jlok: {', '.join(missing_files)}")
            return False
            
        logger.info("‚úÖ A munkafolyamat sikeresen teljes√≠tette a krit√©riumokat")
        return True
    
    def _check_for_errors(self, data: Dict[str, Any]) -> bool:
        """
        Ellen≈ërzi, hogy vannak-e hib√°k az adatokban.
        """
        # Keress√ºnk hib√°kat a kimenetben
        if isinstance(data, dict):
            error_keys = ["error", "exception", "failure"]
            for key in error_keys:
                if key in data:
                    return True
            
            # Rekurz√≠van ellen≈ërizz√ºk a be√°gyazott sz√≥t√°rakat
            for value in data.values():
                if isinstance(value, dict) and self._check_for_errors(value):
                    return True
        
        return False
    
    def _assess_data_quality(self, data: Dict[str, Any]) -> str:
        """
        √ârt√©keli az adatok min≈ës√©g√©t.
        """
        # Egyszer≈± adatmin≈ës√©g-ellen≈ërz√©s
        if not data:
            return "empty"
        
        content_fields = ["content", "text", "body", "html"]
        has_content = any(field in data for field in content_fields)
        
        if not has_content:
            return "low"
        
        # Ellen≈ërizz√ºk a tartalom m√©ret√©t (ha el√©rhet≈ë)
        for field in content_fields:
            if field in data and isinstance(data[field], str):
                content = data[field]
                if len(content) < 100:
                    return "low"
                elif len(content) < 1000:
                    return "medium"
                else:
                    return "high"
        
        return "medium"
    
    def _determine_content_type(self, data: Dict[str, Any]) -> str:
        """
        Meghat√°rozza a tartalom t√≠pus√°t.
        """
        # Tartalom kinyer√©se
        content = ""
        content_fields = ["content", "text", "body", "html"]
        
        for field in content_fields:
            if field in data and isinstance(data[field], str):
                content = data[field]
                break
        
        if not content:
            return "unknown"
        
        # Egyszer≈± heurisztika a tartalom t√≠pus√°nak meghat√°roz√°s√°hoz
        technical_keywords = ["code", "algorithm", "function", "class", "api", 
                            "implementation", "framework", "language", "programming"]
                            
        news_keywords = ["news", "article", "report", "journalist", "published", 
                       "today", "yesterday", "week", "month"]
        
        academic_keywords = ["research", "study", "paper", "academic", "university", 
                           "professor", "journal", "experiment"]
        
        # Egyszer≈± kulcssz√≥ alap√∫ oszt√°lyoz√°s
        technical_count = sum(1 for kw in technical_keywords if kw.lower() in content.lower())
        news_count = sum(1 for kw in news_keywords if kw.lower() in content.lower())
        academic_count = sum(1 for kw in academic_keywords if kw.lower() in content.lower())
        
        # A legt√∂bb tal√°lat alapj√°n d√∂nt√ºnk
        counts = {
            "technical": technical_count,
            "news": news_count,
            "academic": academic_count
        }
        
        max_type = max(counts, key=counts.get)
        max_count = counts[max_type]
        
        # Ha t√∫l kev√©s tal√°lat van, akkor √°ltal√°nos t√≠pus
        if max_count < 3:
            return "general"
            
        return max_type

class WorkflowContextManager:
    """
    Workflow-k √°llapotkezel√©se, kontextus t√°rol√°sa √©s megoszt√°sa
    a k√ºl√∂nb√∂z≈ë komponensek k√∂z√∂tt.
    """
    
    def __init__(self, max_context_size: int = 1024*1024):
        """
        Inicializ√°lja a kontextuskezel≈ët egy maxim√°lis kontextusm√©rettel (alap√©rtelmezetten 1MB).
        """
        self.contexts = {}
        self.max_context_size = max_context_size
    
    def create_workflow_context(self, workflow_id: str = None) -> str:
        """
        L√©trehoz egy √∫j munkafolyamat-kontextust.
        """
        if not workflow_id:
            workflow_id = str(uuid.uuid4())
            
        self.contexts[workflow_id] = {
            "workflow_id": workflow_id,
            "start_time": datetime.now().isoformat(),
            "current_step": "init",
            "completed_steps": [],
            "input_data": {},
            "intermediate_results": {},
            "output_data": {},
            "metadata": {
                "context_size": 0,
                "last_updated": datetime.now().isoformat()
            }
        }
        
        logger.info(f"‚úÖ √öj workflow kontextus l√©trehozva: {workflow_id}")
        return workflow_id
    
    def maintain_workflow_state(self, workflow_id: str, step_results: Dict[str, Any]) -> Dict[str, Any]:
        """
        Karbantartja a munkafolyamat √°llapot√°t a l√©p√©s eredm√©nyeinek hozz√°ad√°s√°val.
        """
        if workflow_id not in self.contexts:
            raise ValueError(f"Nem l√©tez≈ë workflow ID: {workflow_id}")
        
        context = self.contexts[workflow_id]
        
        # L√©p√©s eredm√©nyeinek feldolgoz√°sa
        step_name = step_results.get("step_name", "unknown_step")
        context["current_step"] = step_name
        context["completed_steps"].append(step_name)
        context["intermediate_results"][step_name] = step_results.get("result", {})
        
        # Kontextusm√©ret ellen≈ërz√©se √©s kezel√©se
        self._update_context_size(workflow_id)
        if context["metadata"]["context_size"] > self.max_context_size:
            context = self.compress_large_context(workflow_id)
        
        context["metadata"]["last_updated"] = datetime.now().isoformat()
        self.contexts[workflow_id] = context
        
        return context
    
    def compress_large_context(self, workflow_id: str) -> Dict[str, Any]:
        """
        T√∂m√∂r√≠ti a kontextust, ha az t√∫l nagy lett.
        """
        if workflow_id not in self.contexts:
            raise ValueError(f"Nem l√©tez≈ë workflow ID: {workflow_id}")
            
        logger.info(f"üóúÔ∏è Nagy kontextus t√∂m√∂r√≠t√©se: {workflow_id}")
        
        context = self.contexts[workflow_id]
        
        # Strat√©gia a nagy kontextusok kezel√©s√©re:
        # 1. R√©szletes k√∂ztes eredm√©nyek √∂sszegz√©se
        # 2. Kor√°bbi l√©p√©sek r√©szleteinek elt√°vol√≠t√°sa
        
        # Az utols√≥ N l√©p√©s kiv√©tel√©vel a t√∂bbit √∂sszegezz√ºk
        steps_to_keep_detailed = 2
        completed_steps = context["completed_steps"]
        
        if len(completed_steps) > steps_to_keep_detailed:
            steps_to_summarize = completed_steps[:-steps_to_keep_detailed]
            
            # √ñsszes√≠t√©s l√©trehoz√°sa √©s a r√©szletek elt√°vol√≠t√°sa
            summary = {
                "steps_summarized": steps_to_summarize,
                "timestamp": datetime.now().isoformat()
            }
            
            for step in steps_to_summarize:
                if step in context["intermediate_results"]:
                    # T√°ruljuk el a l√©nyeges inform√°ci√≥kat
                    step_result = context["intermediate_results"][step]
                    if isinstance(step_result, dict):
                        # Csak a legfontosabb mez≈ëk megtart√°sa
                        summary[f"{step}_status"] = "completed"
                        summary[f"{step}_success"] = not self._check_for_errors(step_result)
                        
                        # Ments√ºk el a f√°jlel√©r√©si utakat vagy m√°s fontos eredm√©nyeket
                        if "file_path" in step_result:
                            summary[f"{step}_file"] = step_result["file_path"]
                        if "url" in step_result:
                            summary[f"{step}_url"] = step_result["url"]
                    
                    # T√∂r√∂lj√ºk az eredeti r√©szletes eredm√©nyt
                    del context["intermediate_results"][step]
            
            # A t√∂m√∂r√≠tett √∂sszefoglal√°s hozz√°ad√°sa a kontextushoz
            context["intermediate_results"]["summarized_steps"] = summary
        
        # Kontextus m√©ret friss√≠t√©se
        self._update_context_size(workflow_id)
        logger.info(f"‚úÖ Kontextus t√∂m√∂r√≠tve: {workflow_id} (√∫j m√©ret: {context['metadata']['context_size']} byte)")
        
        return context
    
    def provide_context_to_tools(self, workflow_id: str, tool_name: str) -> Dict[str, Any]:
        """
        El≈ëk√©sz√≠ti √©s biztos√≠tja a megfelel≈ë kontextust egy eszk√∂z sz√°m√°ra.
        """
        if workflow_id not in self.contexts:
            raise ValueError(f"Nem l√©tez≈ë workflow ID: {workflow_id}")
            
        context = self.contexts[workflow_id]
        
        # Alap√©rtelmezett √©s eszk√∂zspecifikus kontextus √∂ssze√°ll√≠t√°sa
        tool_context = {
            "workflow_id": workflow_id,
            "current_step": context["current_step"],
            "input_data": context["input_data"]
        }
        
        # Eszk√∂zspecifikus kontextus kieg√©sz√≠t√©sek
        # WebPageFetchTool eset√©n
        if "WebPageFetchTool" in tool_name:
            # Csak az URL √©s kapcsol√≥d√≥ inform√°ci√≥k
            tool_context["url"] = context["input_data"].get("url", "")
            
        # FileWriteTool eset√©n
        elif "FileWriteTool" in tool_name:
            # Biztos√≠tsuk a ment√©si helyet
            tool_context["output_dir"] = context["input_data"].get("output_dir", "outputs")
            
            # Ha az el≈ëz≈ë eszk√∂z egy weboldal let√∂lt√©se volt, adjuk hozz√° a webtartalmat
            if context["current_step"] == "web_fetch" and "web_content" in context["intermediate_results"].get("web_fetch", {}):
                tool_context["content"] = context["intermediate_results"]["web_fetch"]["web_content"]
        
        return tool_context
    
    def _update_context_size(self, workflow_id: str) -> None:
        """
        Friss√≠ti a kontextus m√©ret√©t.
        """
        if workflow_id not in self.contexts:
            return
            
        context = self.contexts[workflow_id]
        
        # JSON m√©ret becsl√©se
        try:
            context_json = json.dumps(context)
            context_size = len(context_json)
            context["metadata"]["context_size"] = context_size
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Nem siker√ºlt friss√≠teni a kontextus m√©ret√©t: {e}")
    
    def _check_for_errors(self, data: Dict[str, Any]) -> bool:
        """
        Ellen≈ërzi, hogy vannak-e hib√°k az adatokban.
        """
        if isinstance(data, dict):
            error_keys = ["error", "exception", "failure"]
            return any(key in data for key in error_keys)
        return False

class WebContentAnalyzer:
    """
    Web Content Analyzer - Intelligens munkafolyamat a webtartalom elemz√©s√©re
    t√∂bbl√©pcs≈ës feldolgoz√°ssal √©s kontextustudatos d√∂nt√©sekkel.
    
    A munkafolyamat LangGraph integr√°ci√≥t haszn√°l az intelligens d√∂nt√©shozatal 
    √©s felt√©teles el√°gaz√°sok megval√≥s√≠t√°s√°ra.
    """
    
    def __init__(self, output_dir: str = None):
        """
        Inicializ√°lja a Web Content Analyzer munkafolyamatot.
        """
        self.output_dir = output_dir or os.path.join(os.getcwd(), "analysis_results")
        os.makedirs(self.output_dir, exist_ok=True)
        
        # Komponensek inicializ√°l√°sa
        self.orchestrator = SmartToolOrchestrator()
        self.decision_engine = WorkflowDecisionEngine()
        self.context_manager = WorkflowContextManager()
        
        # Munkafolyamat √°llapota
        self.workflow_id = None
        self.graph = None
    
    async def initialize(self):
        """
        Inicializ√°lja a sz√ºks√©ges komponenseket √©s eszk√∂z√∂ket, 
        valamint l√©trehozza a LangGraph munkafolyamatot.
        """
        try:
            await self.orchestrator.register_available_tools()
            self.workflow_id = self.context_manager.create_workflow_context()
            
            # LangGraph munkafolyamat l√©trehoz√°sa
            await self._create_workflow_graph()
            
            logger.info("‚úÖ Web Content Analyzer inicializ√°lva")
            return True
        except Exception as e:
            logger.error(f"‚ùå Hiba a Web Content Analyzer inicializ√°l√°sakor: {e}")
            return False
    
    async def _create_workflow_graph(self):
        """
        L√©trehozza a Web Content Analysis munkafolyamat LangGraph √°llapotgr√°fj√°t.
        """
        # Munkafolyamat √°llapot√°nak defini√°l√°sa
        class WebAnalysisState(WorkflowState):
            """Web Content Analysis √°llapot"""
            url: Optional[str]
            content: Optional[str]
            content_type: Optional[str]
            analysis_results: Optional[Dict[str, Any]]
            keywords: Optional[List[str]]
            branch: Optional[str]
            
        # Gr√°f l√©trehoz√°sa a defini√°lt √°llapott√≠pussal
        builder = StateGraph(WebAnalysisState)
        
        # Csom√≥pontok defini√°l√°sa
        
        # 1. Inicializ√°l√≥ csom√≥pont
        async def initialize_node(state: Dict[str, Any]) -> Dict[str, Any]:
            """A munkafolyamat kezdeti be√°ll√≠t√°sa"""
            logger.info("üöÄ Web Content Analyzer munkafolyamat inicializ√°l√°sa")
            
            new_state = state.copy()
            new_state["workflow_id"] = self.workflow_id
            new_state["start_time"] = datetime.now().isoformat()
            new_state["metadata"] = {"created_by": "WebContentAnalyzer", "version": "0.3.0"}
            
            # K√ºld√ºnk esem√©nyt a diagnosztikai rendszernek
            try:
                from core.event_bus import event_bus
                await event_bus.publish("workflow.start", {
                    "graph_id": self.workflow_id,
                    "state": new_state
                })
            except ImportError:
                logger.warning("‚ö†Ô∏è Event bus nem el√©rhet≈ë, nem k√ºldhet≈ë workflow.start esem√©ny")
                
            return new_state
        
        # 2. Web tartalom let√∂lt√©se
        async def fetch_web_content(state: Dict[str, Any]) -> Dict[str, Any]:
            """Weboldal tartalm√°nak let√∂lt√©se"""
            logger.info("üåê Weboldal tartalom let√∂lt√©se")
            
            new_state = state.copy()
            try:
                url = state.get("url", "")
                if not url:
                    raise ValueError("Hi√°nyz√≥ URL a weblap let√∂lt√©s√©hez")
                    
                web_tool_name, web_tool = await self.orchestrator.select_best_tool(
                    "web page fetch", {"url": url}
                )
                
                web_result = await web_tool.execute(url=url)
                
                # Hibakezel√©s
                if "error" in web_result:
                    raise ValueError(f"Nem siker√ºlt let√∂lteni a weboldalt: {web_result['error']}")
                
                content = web_result.get("content", "")
                raw_content_path = os.path.join(self.output_dir, "raw_content.txt")
                
                # Tartalom ment√©se f√°jlba
                file_tool_name, file_tool = await self.orchestrator.select_best_tool(
                    "write file", {"output_dir": self.output_dir}
                )
                
                await file_tool.execute(path=raw_content_path, content=content)
                
                # √Ållapot friss√≠t√©se
                new_state["content"] = content
                new_state["raw_content_path"] = raw_content_path
                new_state["current_step"] = "web_fetch"
                
                logger.info("‚úÖ Weboldal tartalom sikeresen let√∂ltve")
            except Exception as e:
                logger.error(f"‚ùå Hiba a weboldal let√∂lt√©se k√∂zben: {e}")
                new_state["errors"] = new_state.get("errors", []) + [{
                    "step": "web_fetch",
                    "error": str(e),
                    "timestamp": datetime.now().isoformat()
                }]
            
            return new_state
            
        # 3. Tartalom elemz√©se
        async def analyze_content(state: Dict[str, Any]) -> Dict[str, Any]:
            logger.info("üîç Tartalom elemz√©se (DEBUG)")
            logger.debug(f"[DEBUG] analyze_content state: {state}")
            new_state = state.copy()
            try:
                content = state.get("content", "")
                if not content:
                    raise ValueError("Nincs tartalom az elemz√©shez")
                    
                # Alapszint≈± elemz√©s
                analysis = {
                    "word_count": len(content.split()),
                    "content_length": len(content),
                    "has_code": "```" in content or "<code>" in content,
                    "analyzed_at": datetime.now().isoformat()
                }
                
                # Tartalomt√≠pus meghat√°roz√°sa
                content_type = self.decision_engine._determine_content_type({"content": content})
                
                # √Ållapot friss√≠t√©se
                new_state["analysis_results"] = analysis
                new_state["content_type"] = content_type
                new_state["current_step"] = "content_analysis"
                
                # Eredm√©nyek ment√©se f√°jlba
                file_tool_name, file_tool = await self.orchestrator.select_best_tool(
                    "write file", {"output_dir": self.output_dir}
                )
                
                analysis_data = {
                    "source_url": state.get("url", ""),
                    "analysis_timestamp": datetime.now().isoformat(),
                    "content_type": content_type,
                    "content_stats": analysis
                }
                
                analysis_json_path = os.path.join(self.output_dir, "analysis_data.json")
                await file_tool.execute(
                    path=analysis_json_path, 
                    content=json.dumps(analysis_data, indent=2)
                )
                
                new_state["analysis_json_path"] = analysis_json_path
                logger.info(f"‚úÖ Tartalom elemz√©s k√©sz. T√≠pus: {content_type}")
                
            except Exception as e:
                logger.error(f"‚ùå Hiba a tartalom elemz√©se k√∂zben: {e}")
                logger.debug(f"[DEBUG] analyze_content exception: {e}")
                new_state["errors"] = new_state.get("errors", []) + [{
                    "step": "content_analysis",
                    "error": str(e),
                    "timestamp": datetime.now().isoformat()
                }]
            logger.debug(f"[DEBUG] analyze_content new_state: {new_state}")
            return new_state
        
        # 4. Kulcsszavak kinyer√©se
        async def extract_keywords(state: Dict[str, Any]) -> Dict[str, Any]:
            logger.info("üîë Kulcsszavak kinyer√©se (DEBUG)")
            logger.debug(f"[DEBUG] extract_keywords state: {state}")
            new_state = state.copy()
            try:
                content = state.get("content", "")
                if not content:
                    raise ValueError("Nincs tartalom a kulcsszavak kinyer√©s√©hez")
                
                # Kulcsszavak kinyer√©se
                keywords = self._extract_keywords(content)
                
                # Eredm√©nyek ment√©se f√°jlba
                file_tool_name, file_tool = await self.orchestrator.select_best_tool(
                    "write file", {"output_dir": self.output_dir}
                )
                
                keywords_json = json.dumps({
                    "keywords": keywords,
                    "extracted_at": datetime.now().isoformat(),
                    "content_type": state.get("content_type", "unknown")
                }, indent=2)
                
                keywords_path = os.path.join(self.output_dir, "keywords_extracted.json")
                await file_tool.execute(path=keywords_path, content=keywords_json)
                
                # √Ållapot friss√≠t√©se
                new_state["keywords"] = keywords
                new_state["keywords_path"] = keywords_path
                new_state["current_step"] = "keywords_extraction"
                
                logger.info(f"‚úÖ Kulcsszavak sikeresen kinyerve: {', '.join(keywords[:5])}")
                
            except Exception as e:
                logger.error(f"‚ùå Hiba a kulcsszavak kinyer√©se k√∂zben: {e}")
                logger.debug(f"[DEBUG] extract_keywords exception: {e}")
                new_state["errors"] = new_state.get("errors", []) + [{
                    "step": "keywords_extraction",
                    "error": str(e),
                    "timestamp": datetime.now().isoformat()
                }]
            logger.debug(f"[DEBUG] extract_keywords new_state: {new_state}")
            return new_state
        
        # 5. Tartalom t√≠pus alapj√°n el√°gaz√°s meghat√°roz√°sa
        async def decide_branch(state: Dict[str, Any]) -> Dict[str, Any]:
            logger.info("üîÄ Feldolgoz√°si √∫tvonal meghat√°roz√°sa (DEBUG)")
            logger.debug(f"[DEBUG] decide_branch state: {state}")
            new_state = state.copy()
            content_type = state.get("content_type", "unknown")
            
            # D√∂nt√©s a tartalom t√≠pusa alapj√°n
            if content_type == "technical":
                branch = "technical_branch"
                logger.info("‚úÖ Technikai tartalom feldolgoz√°si √∫tvonal kiv√°lasztva")
            elif content_type == "academic":
                branch = "academic_branch"
                logger.info("‚úÖ Akad√©miai tartalom feldolgoz√°si √∫tvonal kiv√°lasztva")
            else:
                branch = "general_branch"
                logger.info("‚úÖ √Åltal√°nos tartalom feldolgoz√°si √∫tvonal kiv√°lasztva")
            
            # √Ållapot friss√≠t√©se a kiv√°lasztott √°ggal
            new_state["branch"] = branch
            new_state["current_step"] = "branch_decision"
            
            logger.debug(f"[DEBUG] decide_branch new_state: {new_state}")
            return new_state
            
        # 6. Technical branch: Executive summary gener√°l√°s technikai tartalomhoz
        async def technical_summary(state: Dict[str, Any]) -> Dict[str, Any]:
            """Technikai tartalomhoz optimaliz√°lt √∂sszefoglal√≥ gener√°l√°sa"""
            logger.info("üìò Technikai tartalomhoz √∂sszefoglal√≥ gener√°l√°sa")
            
            new_state = state.copy()
            try:
                # Optimaliz√°lt technikai √∂sszefoglal√≥ gener√°l√°s
                url = state.get("url", "")
                content = state.get("content", "")
                analysis_data = {
                    "content_type": "technical",
                    "keywords": state.get("keywords", [])
                }
                
                summary = self._generate_executive_summary(url, content, analysis_data)
                
                # Technikai r√©szeket kiemel≈ë kieg√©sz√≠t√©s
                if analysis_data["keywords"]:
                    tech_keywords = [k for k in analysis_data["keywords"] 
                                    if k in ["code", "api", "framework", "library", "function", "class", "method"]]
                    if tech_keywords:
                        tech_section = "\n## Technical Details\n\n"
                        tech_section += "This content includes details about:\n"
                        for kw in tech_keywords[:5]:
                            tech_section += f"- {kw.capitalize()}\n"
                        summary += tech_section
                
                # √ñsszefoglal√≥ ment√©se f√°jlba
                file_tool_name, file_tool = await self.orchestrator.select_best_tool(
                    "write file", {"output_dir": self.output_dir}
                )
                
                summary_path = os.path.join(self.output_dir, "executive_summary_technical.md")
                await file_tool.execute(path=summary_path, content=summary)
                
                # √Ållapot friss√≠t√©se
                new_state["summary_path"] = summary_path
                new_state["current_step"] = "technical_summary"
                
                logger.info("‚úÖ Technikai √∂sszefoglal√≥ sikeresen gener√°lva")
                
            except Exception as e:
                logger.error(f"‚ùå Hiba a technikai √∂sszefoglal√≥ gener√°l√°sa k√∂zben: {e}")
                new_state["error"] = {
                    "step": "technical_summary",
                    "message": str(e),
                    "timestamp": datetime.now().isoformat()
                }
            
            return new_state
            
        # 7. Academic branch: Executive summary gener√°l√°s akad√©miai tartalomhoz
        async def academic_summary(state: Dict[str, Any]) -> Dict[str, Any]:
            """Akad√©miai tartalomhoz optimaliz√°lt √∂sszefoglal√≥ gener√°l√°sa"""
            logger.info("üìö Akad√©miai tartalomhoz √∂sszefoglal√≥ gener√°l√°sa")
            
            new_state = state.copy()
            try:
                # Optimaliz√°lt akad√©miai √∂sszefoglal√≥ gener√°l√°s
                url = state.get("url", "")
                content = state.get("content", "")
                analysis_data = {
                    "content_type": "academic",
                    "keywords": state.get("keywords", [])
                }
                
                summary = self._generate_executive_summary(url, content, analysis_data)
                
                # Akad√©miai-specifikus kieg√©sz√≠t√©s
                academic_section = "\n## Research Implications\n\n"
                academic_section += "This research has implications for:\n"
                for kw in analysis_data["keywords"][:3]:
                    academic_section += f"- Further studies in {kw}\n"
                academic_section += "- Development of new methodologies in this field\n"
                academic_section += "- Practical applications of the research findings\n"
                summary += academic_section
                
                # √ñsszefoglal√≥ ment√©se f√°jlba
                file_tool_name, file_tool = await self.orchestrator.select_best_tool(
                    "write file", {"output_dir": self.output_dir}
                )
                
                summary_path = os.path.join(self.output_dir, "executive_summary_academic.md")
                await file_tool.execute(path=summary_path, content=summary)
                
                # √Ållapot friss√≠t√©se
                new_state["summary_path"] = summary_path
                new_state["current_step"] = "academic_summary"
                  logger.info("‚úÖ Akad√©miai √∂sszefoglal√≥ sikeresen gener√°lva")
                
            except Exception as e:
                logger.error(f"‚ùå Hiba az akad√©miai √∂sszefoglal√≥ gener√°l√°sa k√∂zben: {e}")
                new_state["error"] = {
                    "step": "academic_summary",
                    "message": str(e),
                    "timestamp": datetime.now().isoformat()
                }
            
            return new_state
            
        # 8. General branch: Executive summary gener√°l√°s √°ltal√°nos tartalomhoz
        async def general_summary(state: Dict[str, Any]) -> Dict[str, Any]:
            """√Åltal√°nos tartalomhoz √∂sszefoglal√≥ gener√°l√°sa"""
            logger.info("üìÑ √Åltal√°nos tartalomhoz √∂sszefoglal√≥ gener√°l√°sa")
            
            new_state = state.copy()
            try:
                # √Åltal√°nos √∂sszefoglal√≥ gener√°l√°s
                url = state.get("url", "")
                content = state.get("content", "")
                analysis_data = {
                    "content_type": "general",
                    "keywords": state.get("keywords", [])
                }
                
                summary = self._generate_executive_summary(url, content, analysis_data)
                
                # √ñsszefoglal√≥ ment√©se f√°jlba
                file_tool_name, file_tool = await self.orchestrator.select_best_tool(
                    "write file", {"output_dir": self.output_dir}
                )
                
                summary_path = os.path.join(self.output_dir, "executive_summary.md")
                await file_tool.execute(path=summary_path, content=summary)
                
                # √Ållapot friss√≠t√©se
                new_state["summary_path"] = summary_path
                new_state["current_step"] = "general_summary"
                  logger.info("‚úÖ √Åltal√°nos √∂sszefoglal√≥ sikeresen gener√°lva")
                
            except Exception as e:
                logger.error(f"‚ùå Hiba az √°ltal√°nos √∂sszefoglal√≥ gener√°l√°sa k√∂zben: {e}")
                new_state["error"] = {
                    "step": "general_summary",
                    "message": str(e),
                    "timestamp": datetime.now().isoformat()
                }
            
            return new_state
            
        # 9. Javaslatok gener√°l√°sa
        async def generate_recommendations(state: Dict[str, Any]) -> Dict[str, Any]:
            """Javaslatok gener√°l√°sa a elemz√©s eredm√©nyei alapj√°n"""
            logger.info("üí° Javaslatok gener√°l√°sa")
            
            new_state = state.copy()
            try:
                content_type = state.get("content_type", "general")
                keywords = state.get("keywords", [])
                
                # Javaslatok gener√°l√°sa
                recommendations = self._generate_recommendations(content_type, keywords)
                
                # Javaslatok ment√©se f√°jlba
                file_tool_name, file_tool = await self.orchestrator.select_best_tool(
                    "write file", {"output_dir": self.output_dir}
                )
                
                recommendations_path = os.path.join(self.output_dir, "recommended_actions.md")
                await file_tool.execute(path=recommendations_path, content=recommendations)
                
                # √Ållapot friss√≠t√©se
                new_state["recommendations_path"] = recommendations_path
                new_state["current_step"] = "recommendations"
                
                logger.info("‚úÖ Javaslatok sikeresen gener√°lva")
                  except Exception as e:
                logger.error(f"‚ùå Hiba a javaslatok gener√°l√°sa k√∂zben: {e}")
                new_state["error"] = {
                    "step": "recommendations",
                    "message": str(e),
                    "timestamp": datetime.now().isoformat()
                }
            
            return new_state
            
        # 10. √ñsszegz√©s √©s munkafolyamat befejez√©se
        async def finalize_workflow(state: Dict[str, Any]) -> Dict[str, Any]:
            """Munkafolyamat befejez√©se √©s eredm√©nyek √∂sszegz√©se"""
            logger.info("üèÅ Munkafolyamat √∂sszegz√©se √©s befejez√©se")
            
            new_state = state.copy()
            
            # V√©geredm√©ny √∂sszegz√©se
            output_data = {
                "workflow_id": state.get("workflow_id", ""),
                "url": state.get("url", ""),
                "raw_content_path": state.get("raw_content_path", ""),
                "analysis_json_path": state.get("analysis_json_path", ""),
                "keywords_path": state.get("keywords_path", ""),
                "summary_path": state.get("summary_path", ""),
                "recommendations_path": state.get("recommendations_path", ""),
                "content_type": state.get("content_type", "unknown"),
                "completed_at": datetime.now().isoformat(),
                "branch": state.get("branch", "unknown")
            }
            
            # Indexf√°jl gener√°l√°sa az eredm√©nyekr≈ël
            try:
                file_tool_name, file_tool = await self.orchestrator.select_best_tool(
                    "write file", {"output_dir": self.output_dir}
                )
                
                index_content = "# Web Content Analysis Results\n\n"
                index_content += f"Analysis of: {state.get('url', '')}\n"
                index_content += f"Content Type: {state.get('content_type', 'unknown')}\n"
                index_content += f"Completed: {datetime.now().isoformat()}\n\n"
                
                index_content += "## Generated Files\n\n"
                for name, path in output_data.items():
                    if name.endswith("_path") and path:
                        file_name = os.path.basename(path)
                        index_content += f"- {name.replace('_path', '')}: [{file_name}]({file_name})\n"
                
                index_path = os.path.join(self.output_dir, "analysis_index.md")
                await file_tool.execute(path=index_path, content=index_content)
                output_data["index_path"] = index_path
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Hiba az index gener√°l√°sa k√∂zben: {e}")
            
            # √Ållapot friss√≠t√©se
            new_state["output_data"] = output_data
            new_state["current_step"] = "completed"
            new_state["end_time"] = datetime.now().isoformat()
            
            # Esem√©ny k√ºld√©se a diagnosztikai rendszernek
            try:
                from core.event_bus import event_bus
                await event_bus.publish("workflow.complete", {
                    "graph_id": self.workflow_id,
                    "state": new_state
                })
            except ImportError:
                logger.warning("‚ö†Ô∏è Event bus nem el√©rhet≈ë, nem k√ºldhet≈ë workflow.complete esem√©ny")
                
            logger.info("‚úÖ Munkafolyamat sikeresen befejezve")
            return new_state
          # Hibakezel≈ë csom√≥pont
        async def handle_errors(state: Dict[str, Any]) -> Dict[str, Any]:
            """Hibakezel√©s a munkafolyamat sor√°n"""
            logger.error("‚ùå Hibakezel√©si csom√≥pont aktiv√°lva")
            
            new_state = state.copy()
            error = new_state.get("error", {})
            
            # Hiba r√©szletek napl√≥z√°sa
            if error:
                logger.error(f"  - {error.get('step', 'unknown')}: {error.get('message', 'ismeretlen hiba')}")
            
            # Hiba jelent√©s gener√°l√°sa
            try:
                file_tool_name, file_tool = await self.orchestrator.select_best_tool(
                    "write file", {"output_dir": self.output_dir}
                )
                
                error_report = "# Web Content Analysis Error Report\n\n"
                error_report += f"Analysis of: {state.get('url', '')}\n"
                error_report += f"Generated: {datetime.now().isoformat()}\n\n"
                
                error_report += "## Error Encountered\n\n"
                if error:
                    error_report += f"### Step: {error.get('step', 'unknown')}\n"
                    error_report += f"Error: {error.get('message', 'unknown error')}\n"
                    error_report += f"Time: {error.get('timestamp', '')}\n\n"
                  error_report += "\n## Diagnostic Information\n\n"
                error_report += f"- Workflow ID: {state.get('workflow_id', 'unknown')}\n"
                error_report += f"- Current step when error occurred: {state.get('current_step', 'unknown')}\n"
                
                error_path = os.path.join(self.output_dir, "error_report.md")
                await file_tool.execute(path=error_path, content=error_report)
                
                new_state["error_report_path"] = error_path
                
            except Exception as e:
                logger.error(f"‚ùå Hiba a hibajelent√©s ment√©se k√∂zben: {str(e)}")
            
            # Esem√©ny k√ºld√©se a diagnosztikai rendszernek
            try:
                from core.event_bus import event_bus
                await event_bus.publish("workflow.error", {
                    "graph_id": self.workflow_id,
                    "error": f"Error encountered: {error.get('message', 'Unknown error')}",
                    "state": new_state
                })
            except ImportError:
                logger.warning("‚ö†Ô∏è Event bus nem el√©rhet≈ë, nem k√ºldhet≈ë workflow.error esem√©ny")
            
            return new_state
        
        # Csom√≥pontok hozz√°ad√°sa a gr√°fhoz
        builder.add_node("initialize", initialize_node)
        builder.add_node("fetch_content", fetch_web_content)
        builder.add_node("analyze_content", analyze_content)
        builder.add_node("extract_keywords", extract_keywords)
        builder.add_node("decide_branch", decide_branch)
        builder.add_node("technical_summary", technical_summary)
        builder.add_node("academic_summary", academic_summary)
        builder.add_node("general_summary", general_summary)
        builder.add_node("generate_recommendations", generate_recommendations)
        builder.add_node("finalize", finalize_workflow)
        builder.add_node("handle_errors", handle_errors)
          # Csak az els≈ë √©l marad itt, a t√∂bbit a conditional edges kezelik
        builder.add_edge("initialize", "fetch_content")
        
        # Felt√©teles el√°gaz√°sok a tartalom t√≠pusa alapj√°n
        builder.add_conditional_edges(
            "decide_branch",
            lambda state: state.get("branch"),
            {
                "technical_branch": "technical_summary",
                "academic_branch": "academic_summary",
                "general_branch": "general_summary",
            }
        )
        
        # √ñsszefut√≥ √©lek - mindegyik √∂sszefoglal√≥ ut√°n javaslatok gener√°l√°sa
        builder.add_edge("technical_summary", "generate_recommendations")
        builder.add_edge("academic_summary", "generate_recommendations")
        builder.add_edge("general_summary", "generate_recommendations")
        
        # Befejez≈ë √©l
        # Alapvet≈ë munkafolyamat √∫tvonal vissza√°ll√≠t√°sa
        builder.add_edge("fetch_content", "analyze_content")
        builder.add_edge("analyze_content", "extract_keywords")
        builder.add_edge("extract_keywords", "decide_branch")
          # Hiba ellen≈ërz≈ë f√ºggv√©ny
        def has_errors(state):
            return "error" in state and state.get("error") is not None
        
        # Hibakezel√©s felt√©teles √©lek hozz√°ad√°sa minden l√©p√©shez
        for node in ["fetch_content", "analyze_content", "extract_keywords"]:
            builder.add_conditional_edges(
                node,
                has_errors,
                {
                    True: "handle_errors"
                    # Ha False, a m√°r defini√°lt √©lek alapj√°n folytatja
                }
            )
            
        # √ñsszefoglal√≥ t√≠pus√∫ csom√≥pontok egyedi hibakezel√©se
        for node in ["technical_summary", "academic_summary", "general_summary"]:
            builder.add_conditional_edges(
                node,
                has_errors,
                {
                    True: "handle_errors",
                    # Ha False, akkor a recommendations node-ra megy, ami m√°r defini√°lva van
                }
            )
            
        # Javaslatok gener√°l√°sa ut√°n vagy a befejez√©sre vagy a hibakezel√©sre megy
        builder.add_conditional_edges(
            "generate_recommendations",
            has_errors,
            {
                True: "handle_errors",
                False: "finalize"
            }
        )
        
        # A hibakezel≈ë ut√°n befejez√©s
        builder.add_edge("handle_errors", "finalize")
        
        # Entrypoint be√°ll√≠t√°sa
        builder.set_entry_point("initialize")
        
        # Gr√°f l√©trehoz√°sa √©s be√°ll√≠t√°sa
        self.graph = builder.compile()
        
        logger.info("‚úÖ Web Content Analysis munkafolyamat gr√°f sikeresen l√©trehozva")
    
    async def analyze_url(self, url: str) -> Dict[str, Any]:
        """
        Teljes webtartalom-elemz≈ë munkafolyamat v√©grehajt√°sa egy URL-en,
        LangGraph alap√∫ intelligens feldolgoz√°ssal √©s hibakezel√©ssel.
        """
        logger.info(f"üöÄ Web Content Analyzer ind√≠t√°sa az URL-re: {url}")
        
        if not self.workflow_id or not self.graph:
            logger.error("‚ùå A munkafolyamat nincs inicializ√°lva")
            return {"success": False, "error": "A munkafolyamat nincs inicializ√°lva"}
        
        try:
            # Kezdeti √°llapot l√©trehoz√°sa
            initial_state = {
                "url": url,
                "output_dir": self.output_dir,
                "workflow_id": self.workflow_id,
                "errors": []
            }            # Munkafolyamat v√©grehajt√°sa
            logger.info("‚ö° LangGraph munkafolyamat ind√≠t√°sa...")
            try:
                # Pr√≥b√°ljuk el≈ësz√∂r az async m√≥dszert
                if hasattr(self.graph, 'ainvoke'):
                    result_state = await self.graph.ainvoke(initial_state)
                elif hasattr(self.graph, 'invoke'):
                    logger.info("‚ö° Szinkron v√©grehajt√°s haszn√°lata...")
                    result_state = self.graph.invoke(initial_state)
                else:
                    raise RuntimeError('LangGraph StateGraph does not support ainvoke/invoke/arun/run methods!')
            except Exception as e:
                logger.error(f"‚ùå Hiba a munkafolyamat v√©grehajt√°sa k√∂zben: {str(e)}")
                raise
                
            # Eredm√©nyek ellen≈ërz√©se √©s visszaad√°sa
            if "errors" in result_state and result_state["errors"]:
                logger.error("‚ùå A munkafolyamat hib√°kkal fejez≈ëd√∂tt be")
                return {
                    "success": False, 
                    "error": "A munkafolyamat hib√°kkal fejez≈ëd√∂tt be",
                    "errors": result_state["errors"],
                    "partial_results": result_state.get("output_data", {})
                }
            
            # Sikeres befejez√©s
            logger.info("‚úÖ Web Content Analysis munkafolyamat sikeresen befejezve!")
            
            return {
                "success": True,
                "workflow_id": self.workflow_id,
                "output_paths": result_state.get("output_data", {}),
                "content_type": result_state.get("content_type", "unknown"),
                "processing_branch": result_state.get("branch", "unknown")
            }
            
        except Exception as e:
            logger.error(f"‚ùå Kritikus hiba a webtartalom elemz√©se sor√°n: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def _extract_keywords(self, content: str) -> List[str]:
        """
        Egyszer≈± kulcssz√≥kinyer√©s a tartalomb√≥l.
        """
        # Val√≥di implement√°ci√≥ban itt NLP-t haszn√°ln√°nk
        # Most csak egy egyszer≈± implement√°ci√≥
        import re
        from collections import Counter
        
        # Tiszt√≠tsuk meg a HTML-t≈ël
        content_clean = re.sub(r'<[^>]+>', ' ', content)
        
        # Tokeniz√°l√°s egyszer≈± szavakra
        words = re.findall(r'\b[a-zA-Z]{4,}\b', content_clean.lower())
        
        # Stopszavak (gyakori szavak, amelyeket ki akarunk sz≈±rni)
        stopwords = set([
            "this", "that", "these", "those", "the", "and", "but", "for", "with",
            "about", "from", "when", "where", "what", "which", "who", "whom", "whose"
        ])
        
        # Stopszavak elt√°vol√≠t√°sa
        filtered_words = [word for word in words if word not in stopwords]
        
        # Leggyakoribb szavak megtal√°l√°sa
        counter = Counter(filtered_words)
        top_keywords = [word for word, count in counter.most_common(15)]
        
        return top_keywords
    
    def _generate_executive_summary(self, url: str, content: str, analysis_data: Dict[str, Any]) -> str:
        """
        Executive summary gener√°l√°s a tartalomb√≥l.
        """
        # Val√≥di implement√°ci√≥ban itt AI-t haszn√°ln√°nk
        keywords = ", ".join(analysis_data.get("keywords", [])[:5])
        word_count = analysis_data.get("content_stats", {}).get("word_count", 0)
        content_type = analysis_data.get("content_type", "unknown")
        
        return f"""# Executive Summary

## Content Overview

Source: {url}
Content Type: {content_type.capitalize()}
Length: {word_count} words
Primary Keywords: {keywords}

## Key Insights

This {content_type} content explores topics related to {keywords}. 
The material provides information about various aspects of these subjects and their relationships.

## Summary

The content from {url} discusses {content_type} topics with a focus on {keywords}.
It's structured in a way that presents the information in a coherent manner.

## Relevance

Based on the keywords and content, this material would be relevant for audiences interested in 
{content_type} content, particularly those focused on {keywords}.

## Recommendations

Further analysis is recommended to extract more specific insights and potential applications.

*Generated by Web Content Analyzer at {datetime.now().isoformat()}*
"""
    
    def _generate_recommendations(self, content_type: str, keywords: List[str]) -> str:
        """
        Gener√°lja a javasolt k√∂vetkez≈ë l√©p√©seket a tartalom t√≠pusa alapj√°n.
        """
        # Kulcsszavak list√°j√°b√≥l v√©letlenszer≈±en v√°lasszunk ki p√°rat
        import random
        selected_keywords = random.sample(keywords, min(3, len(keywords)))
        keywords_str = ", ".join(selected_keywords)
        
        recommendations = f"""# Recommended Follow-up Actions

Based on the analysis of the content, the following actions are recommended:

"""
        
        # Tartalomt√≠pus-specifikus javaslatok
        if content_type == "technical":
            recommendations += f"""## Technical Content Recommendations

1. **Research Related Technical Documentation**
   - Look for official documentation related to {keywords_str}
   - Search for code samples and implementation guides

2. **Code Implementation**
   - Create a proof-of-concept using the described techniques
   - Test the implementation with various scenarios

3. **Expert Consultation**
   - Connect with subject matter experts in {selected_keywords[0] if selected_keywords else "this field"}
   - Join relevant technical communities and forums

4. **Technical Comparison**
   - Compare with alternative approaches or technologies
   - Evaluate performance and scalability considerations
"""
        elif content_type == "academic":
            recommendations += f"""## Academic Content Recommendations

1. **Literature Review**
   - Search for related papers in academic databases
   - Review cited references and bibliography

2. **Methodology Evaluation**
   - Analyze the research methodology for validity
   - Consider replication studies or extensions

3. **Cross-disciplinary Connections**
   - Explore how this research connects to other fields
   - Identify potential applications in related domains

4. **Research Collaboration**
   - Identify institutions working on {keywords_str}
   - Connect with researchers in this field
"""
        else:
            recommendations += f"""## General Content Recommendations

1. **Further Information Gathering**
   - Search for additional sources on {keywords_str}
   - Explore different perspectives on the topic

2. **Content Validation**
   - Cross-reference with reputable sources
   - Verify factual claims and data

3. **Broader Context**
   - Understand how this topic relates to wider trends
   - Consider historical development and future directions

4. **Practical Applications**
   - Identify how this information can be applied
   - Develop actionable insights based on the content
"""
        
        recommendations += f"""
## Priority Actions

1. **High Priority**: Research more about {selected_keywords[0] if selected_keywords else "the main topic"}
2. **Medium Priority**: Connect with communities focused on {keywords_str}
3. **Ongoing**: Monitor for updates and new developments in this area

*Generated by Web Content Analyzer at {datetime.now().isoformat()}*
"""
        
        return recommendations

async def main():
    """
    F≈ë bel√©p√©si pont a Web Content Analyzer futtat√°s√°hoz.
    """
    logger.info("=" * 50)
    logger.info("Web Content Analyzer - Intelligens Workflow Demo")
    logger.info("=" * 50)
    
    import argparse
    parser = argparse.ArgumentParser(description="Web Content Analyzer")
    parser.add_argument("--url", type=str, default="https://openai.com/research/gpt-4", 
                     help="Az elemzend≈ë URL")
    args = parser.parse_args()
    
    try:
        # Analyzer inicializ√°l√°sa
        analyzer = WebContentAnalyzer()
        await analyzer.initialize()
        
        # URL elemz√©se
        logger.info(f"üåê URL elemz√©se: {args.url}")
        result = await analyzer.analyze_url(args.url)
        
        # Eredm√©nyek ki√≠r√°sa
        if result["success"]:
            logger.info("‚úÖ Elemz√©s sikeresen befejezve!")
            logger.info("üìÅ Eredm√©nyek:")
            for output_name, output_path in result.get("output_paths", {}).items():
                logger.info(f"  - {output_name}: {output_path}")
        else:
            logger.error(f"‚ùå Elemz√©s sikertelen: {result.get('error', 'Ismeretlen hiba')}")
            
    except Exception as e:
        logger.error(f"‚ùå Hiba a program fut√°sa k√∂zben: {str(e)}")
        traceback.print_exc()
    
    logger.info("=" * 50)
    logger.info("Web Content Analyzer - Futtat√°s befejezve")
    logger.info("=" * 50)

if __name__ == "__main__":
    asyncio.run(main())
