system:
  log_level: INFO
  name: Project-S
  version: 0.1.0

# Adding Qwen3 config
qwen3:
  enabled: true
  interface: "llama_cpp"  # or "ollama"
  llama_cpp:
    model_path: "/path/to/qwen3.gguf"
    n_ctx: 4096
    n_gpu_layers: 35
    n_threads: 8
  ollama:
    model_name: "qwen3"
    api_base: "http://localhost:11434/api"
  temperature: 0.7
  max_tokens: 2048
  system_prompt: "You are a helpful AI assistant that specializes in coding and software development."
