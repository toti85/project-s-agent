#!/usr/bin/env python3
"""
System Verification Script
Tests the Project-S system to ensure all critical issues are resolved
"""

import asyncio
import sys
import os
import logging

# Add the project root to the Python path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

async def main():
    print("ğŸ” Project-S System Verification")
    print("=" * 40)
    
    try:
        # Test 1: Import core components
        print("ğŸ“¦ Testing core imports...")
        from core.cognitive_core_langgraph import CognitiveCoreWithLangGraph
        from llm_clients.qwen_client import QwenOllamaClient
        from core.multi_model_integration import MultiModelManager
        from llm_clients.model_selector import get_model_client
        print("âœ… All core imports successful")
        
        # Test 2: LangGraph compatibility
        print("\nğŸ§  Testing LangGraph compatibility...")
        try:
            # This should not fail with aput() errors anymore
            cognitive_core = CognitiveCoreWithLangGraph()
            print("âœ… LangGraph cognitive core initialized successfully")
        except Exception as e:
            print(f"âŒ LangGraph error: {e}")
            return False
        
        # Test 3: QwenOllamaClient ask method
        print("\nğŸ’¬ Testing QwenOllamaClient ask method...")
        try:
            qwen_client = QwenOllamaClient(model="qwen2.5:latest")
            has_ask = hasattr(qwen_client, 'ask')
            print(f"âœ… QwenOllamaClient has 'ask' method: {has_ask}")
            if not has_ask:
                return False
        except Exception as e:
            print(f"âŒ QwenOllamaClient error: {e}")
            return False
        
        # Test 4: Model selector returns QwenOllamaClient
        print("\nğŸ¯ Testing model selector...")
        try:
            ollama_client = get_model_client("ollama", "qwen2.5:latest")
            is_qwen_client = isinstance(ollama_client, QwenOllamaClient)
            print(f"âœ… Model selector returns QwenOllamaClient: {is_qwen_client}")
            if not is_qwen_client:
                return False
        except Exception as e:
            print(f"âŒ Model selector error: {e}")
            return False
        
        # Test 5: Multi-model integration fallback
        print("\nğŸ”„ Testing multi-model integration fallback...")
        try:
            manager = MultiModelManager()
            print("âœ… MultiModelManager initialized successfully")
        except Exception as e:
            print(f"âŒ MultiModelManager error: {e}")
            return False
        
        # Test 6: Unicode encoding (Windows console)
        print("\nğŸ“ Testing Unicode encoding...")
        try:
            # This should work on Windows console now
            test_string = "ğŸš€ Test emoji output: âœ… âŒ ğŸ¯ ğŸ”"
            print(test_string)
            print("âœ… Unicode encoding working properly")
        except Exception as e:
            print(f"âŒ Unicode encoding error: {e}")
            return False
        
        print("\n" + "=" * 40)
        print("ğŸ‰ ALL CRITICAL ISSUES RESOLVED!")
        print("âœ… LangGraph 0.0.69 compatibility")
        print("âœ… OllamaClient 'ask' method")
        print("âœ… Unicode encoding")
        print("âœ… Multi-model fallback system")
        print("\nğŸ’ª The system is now ready for complex workflow execution!")
        return True
        
    except Exception as e:
        print(f"\nâŒ Critical error: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
