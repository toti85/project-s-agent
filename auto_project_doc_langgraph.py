"""
Project-S Automatikus Projekt Dokument√°ci√≥ Gener√°l√≥ - LangGraph Verzi√≥
-------------------------------------------------------------------
Ez a modul a Project-S eszk√∂z rendszer√©t haszn√°lja egy komplex,
t√∂bb AI-t haszn√°l√≥ dokument√°ci√≥ gener√°l√≥ workflow l√©trehoz√°s√°ra, LangGraph integr√°ci√≥val.

Az implement√°ci√≥ a m√°r megl√©v≈ë auto_project_doc_generator.py eszk√∂zre √©p√≠t, de
a folyamatokat egy LangGraph munkafolyamatban szervezi, ami lehet≈ëv√© teszi:
1. Az eszk√∂z√∂k modul√°ris munkafolyamatba szervez√©s√©t
2. A t√∂bb AI modell kezel√©s√©t a LangGraph √°ltal
3. A dokument√°ci√≥ gener√°l√°s r√©szfeladatainak elk√ºl√∂n√≠tett kezel√©s√©t
4. A robusztus hibakezel√©st √©s az √°llapot k√∂vet√©s√©t
"""

import asyncio
import logging
import os
import sys
from pathlib import Path
import json
from datetime import datetime
import re
import traceback
from typing import Dict, List, Any, Optional, Tuple, Set, TypedDict, cast

# Hozz√°adjuk a projekt gy√∂k√©rk√∂nyvt√°r√°t a keres√©si √∫tvonalhoz
project_root = Path(__file__).parent
if str(project_root) not in sys.path:
    sys.path.append(str(project_root))

# Konfigur√°ljuk a napl√≥z√°st
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger("auto_doc_langgraph")

# Project-S importok
try:
    from tools import register_all_tools
    from tools.file_tools import FileSearchTool, FileReadTool, FileWriteTool, FileInfoTool
    from tools.web_tools import WebPageFetchTool
    from tools.code_tools import CodeExecutionTool, PythonModuleInfoTool
    from tools.langgraph_integration import tool_graph_integrator, ToolState
    logger.info("Project-S eszk√∂z modulok sikeresen import√°lva")
except ImportError as e:
    logger.error(f"Hiba t√∂rt√©nt a Project-S modulok import√°l√°sakor: {e}")
    sys.exit(1)

# LangGraph importok
try:
    from langgraph.graph import StateGraph
    from langgraph.prebuilt import ToolNode
    from langgraph.graph.message import add_messages
    logger.info("LangGraph modulok sikeresen import√°lva")
except ImportError as e:
    logger.error(f"Hiba t√∂rt√©nt a LangGraph import√°l√°sakor: {e}")
    logger.error("Futtassa a 'pip install langgraph' parancsot a hi√°nyz√≥ k√∂nyvt√°r telep√≠t√©s√©hez.")
    sys.exit(1)

# √öjrahaszn√°ljuk a komponenseket az eredeti f√°jlb√≥l
from auto_project_doc_generator import (
    AIModelIntegration, 
    ProjectStructureAnalyzer,
    DocumentationGenerator,
    update_status
)

# Haszn√°ljuk a megosztott t√≠pusdefin√≠ci√≥kat a k√∂rk√∂r√∂s import√°l√°s elker√ºl√©s√©hez
from tools.langgraph_types import DocGenState

# Munkafolyamat √°llapot inicializ√°l√°sa
def init_docgen_state(project_path: str) -> DocGenState:
    """
    Inicializ√°lja a dokument√°ci√≥ gener√°l√≥ munkafolyamat √°llapot√°t.
    """
    return cast(DocGenState, {
        "messages": [
            {
                "role": "system",
                "content": "Automatikus projekt dokument√°ci√≥ gener√°l√°s munkafolyamat indul√°sa."
            }
        ],
        "tools": [],
        "tool_results": {},
        "tool_history": [],
        "tool_errors": [],
        
        "project_data": {
            "project_path": project_path,
            "python_files": [],
            "config_files": [],
            "doc_files": []
        },
        "file_analysis": {
            "analyzed_files_count": 0,
            "total_files_count": 0,
            "files": []
        },
        "ai_results": {},
        "output_paths": {
            "output_dir": os.path.join(project_path, "outputs"),
            "readme_path": "",
            "analysis_path": ""
        },
        "current_stage": "init"
    })

# LangGraph csom√≥pontok a munkafolyamathoz
async def analyze_project_structure(state: DocGenState) -> DocGenState:
    """
    Elemzi a projekt strukt√∫r√°j√°t √©s friss√≠ti az √°llapotot.
    """
    logger.info("üîç Projekt strukt√∫ra elemz√©se...")
    try:
        analyzer = ProjectStructureAnalyzer()
        project_path = state["project_data"]["project_path"]
        project_data = await analyzer.get_project_structure(project_path)
        
        # Friss√≠tj√ºk az √°llapotot
        state["project_data"] = project_data
        state["current_stage"] = "project_structure_analyzed"
        
        # Hozz√°adunk egy √ºzenetet a munkafolyamat napl√≥z√°s√°hoz
        add_messages(state, [
            {
                "role": "system",
                "content": f"Projekt strukt√∫ra elemz√©se sikeres. Python f√°jlok sz√°ma: {len(project_data.get('python_files', []))}"
            }
        ])
    except Exception as e:
        error_msg = f"Hiba a projekt strukt√∫ra elemz√©sekor: {str(e)}"
        logger.error(error_msg)
        state["tool_errors"].append({
            "stage": "analyze_project_structure",
            "error": error_msg,
            "timestamp": datetime.now().isoformat()
        })
        state["current_stage"] = "error"
        add_messages(state, [
            {
                "role": "system",
                "content": error_msg
            }
        ])
    
    return state

async def analyze_python_files(state: DocGenState) -> DocGenState:
    """
    Elemzi a Python f√°jlok tartalm√°t √©s friss√≠ti az √°llapotot.
    """
    logger.info("üìÑ Python f√°jlok r√©szletes elemz√©se...")
    try:
        analyzer = ProjectStructureAnalyzer()
        python_files = state["project_data"].get("python_files", [])
        
        if not python_files:
            logger.warning("Nem tal√°lhat√≥k Python f√°jlok a projektben.")
            add_messages(state, [
                {
                    "role": "system",
                    "content": "Figyelmeztet√©s: Nem tal√°lhat√≥k Python f√°jlok a projektben."
                }
            ])
            state["current_stage"] = "files_analyzed"
            return state
        
        file_analysis = await analyzer.analyze_python_files(python_files)
        
        # Friss√≠tj√ºk az √°llapotot
        state["file_analysis"] = file_analysis
        state["current_stage"] = "files_analyzed"
        
        # Hozz√°adunk egy √ºzenetet a munkafolyamat napl√≥z√°s√°hoz
        add_messages(state, [
            {
                "role": "system",
                "content": f"F√°jl elemz√©s sikeres. Elemzett f√°jlok sz√°ma: {file_analysis.get('analyzed_files_count', 0)}"
            }
        ])
    except Exception as e:
        error_msg = f"Hiba a Python f√°jlok elemz√©sekor: {str(e)}"
        logger.error(error_msg)
        state["tool_errors"].append({
            "stage": "analyze_python_files",
            "error": error_msg,
            "timestamp": datetime.now().isoformat()
        })
        state["current_stage"] = "error"
        add_messages(state, [
            {
                "role": "system",
                "content": error_msg
            }
        ])
    
    return state

async def perform_ai_analysis(state: DocGenState) -> DocGenState:
    """
    AI modellek haszn√°lata a k√≥d elemz√©s√©hez.
    """
    logger.info("üß† AI elemz√©s v√©grehajt√°sa...")
    try:
        ai_integration = AIModelIntegration()
        project_data = state["project_data"]
        file_analysis = state["file_analysis"]
        context = {"project_data": project_data, "file_analysis": file_analysis}
        
        # GPT-4 haszn√°lata architekt√∫ra elemz√©shez
        logger.info("GPT-4 haszn√°lata architekt√∫ra elemz√©shez")
        architecture_result = await ai_integration.analyze_with_model(
            model="gpt-4", 
            prompt="Elemezd a projekt architekt√∫r√°j√°t √©s azonos√≠tsd a f≈ë design pattern-eket.",
            context=context
        )
        
        # GPT-4 haszn√°lata k√≥d strukt√∫ra elemz√©shez
        logger.info("GPT-4 haszn√°lata k√≥d strukt√∫ra elemz√©shez")
        code_structure_result = await ai_integration.analyze_with_model(
            model="gpt-4", 
            prompt="Elemezd a projekt k√≥d strukt√∫r√°j√°t √©s f≈ë komponenseit.",
            context=context
        )
        
        # Claude haszn√°lata best practices elemz√©shez
        logger.info("Claude haszn√°lata best practices elemz√©shez")
        best_practices_result = await ai_integration.analyze_with_model(
            model="claude-sonnet", 
            prompt="√ârt√©keld a k√≥d min≈ës√©g√©t √©s aj√°nlj best practices technik√°kat.",
            context=context
        )
        
        # Claude haszn√°lata biztons√°gi elemz√©shez
        logger.info("Claude haszn√°lata biztons√°gi elemz√©shez")
        security_result = await ai_integration.analyze_with_model(
            model="claude-sonnet", 
            prompt="√ârt√©keld a projekt biztons√°gi aspektusait, k√ºl√∂n√∂sen a k√≥d futtat√°s √©s rendszerparancs v√©grehajt√°s szempontj√°b√≥l.",
            context=context
        )
        
        # Friss√≠tj√ºk az √°llapotot
        state["ai_results"] = {
            "architecture": architecture_result,
            "code_structure": code_structure_result,
            "best_practices": best_practices_result,
            "security": security_result
        }
        state["current_stage"] = "ai_analysis_completed"
        
        # Hozz√°adunk egy √ºzenetet a munkafolyamat napl√≥z√°s√°hoz
        add_messages(state, [
            {
                "role": "system",
                "content": "AI elemz√©s sikeresen v√©grehajtva mindk√©t modellel (GPT-4 √©s Claude)"
            }
        ])
    except Exception as e:
        error_msg = f"Hiba az AI elemz√©s sor√°n: {str(e)}"
        logger.error(error_msg)
        state["tool_errors"].append({
            "stage": "perform_ai_analysis",
            "error": error_msg,
            "timestamp": datetime.now().isoformat()
        })
        state["current_stage"] = "error"
        add_messages(state, [
            {
                "role": "system",
                "content": error_msg
            }
        ])
    
    return state

async def generate_documentation(state: DocGenState) -> DocGenState:
    """
    Dokument√°ci√≥ gener√°l√°s az √∂sszegy≈±jt√∂tt adatok alapj√°n.
    """
    logger.info("üìù Dokument√°ci√≥ gener√°l√°sa...")
    try:
        output_dir = state["output_paths"]["output_dir"]
        os.makedirs(output_dir, exist_ok=True)
        
        doc_generator = DocumentationGenerator(output_dir)
        project_data = state["project_data"]
        file_analysis = state["file_analysis"]
        ai_results = state["ai_results"]
        
        # README.md gener√°l√°sa
        readme_path = await doc_generator.generate_readme(project_data, ai_results)
        
        # PROJECT_ANALYSIS.md gener√°l√°sa
        analysis_path = await doc_generator.generate_project_analysis(project_data, file_analysis, ai_results)
        
        # Friss√≠tj√ºk az √°llapotot
        state["output_paths"]["readme_path"] = readme_path
        state["output_paths"]["analysis_path"] = analysis_path
        state["current_stage"] = "documentation_generated"
        
        # Hozz√°adunk egy √ºzenetet a munkafolyamat napl√≥z√°s√°hoz
        add_messages(state, [
            {
                "role": "system",
                "content": f"Dokument√°ci√≥ gener√°l√°s sikeres. L√©trehozott f√°jlok:\n- README.md: {readme_path}\n- PROJECT_ANALYSIS.md: {analysis_path}"
            }
        ])
    except Exception as e:
        error_msg = f"Hiba a dokument√°ci√≥ gener√°l√°sa sor√°n: {str(e)}"
        logger.error(error_msg)
        state["tool_errors"].append({
            "stage": "generate_documentation",
            "error": error_msg,
            "timestamp": datetime.now().isoformat()
        })
        state["current_stage"] = "error"
        add_messages(state, [
            {
                "role": "system",
                "content": error_msg
            }
        ])
    
    return state

async def update_project_status(state: DocGenState) -> DocGenState:
    """
    Friss√≠ti a PROJECT_STATUS.md f√°jlt a folyamat √°llapot√°val.
    """
    logger.info("üìä PROJECT_STATUS.md friss√≠t√©se...")
    try:
        project_path = state["project_data"]["project_path"]
        status_path = os.path.join(project_path, "PROJECT_STATUS.md")
        
        # √Ållapot √ºzenet √∂ssze√°ll√≠t√°sa a munkafolyamat eredm√©nye alapj√°n
        if state["current_stage"] == "documentation_generated":
            status = {
                "current_task": "Automatikus projekt dokument√°ci√≥ gener√°l√°s (LangGraph verzi√≥)",
                "last_modification": "Dokument√°ci√≥ gener√°l√°s befejezve, README.md √©s PROJECT_ANALYSIS.md elk√©sz√ºlt",
                "next_step": "A gener√°lt dokument√°ci√≥ ellen≈ërz√©se √©s finomhangol√°sa",
                "new_files": {
                    "auto_project_doc_langgraph.py": "‚úÖ [√öj]",
                    "outputs/README.md": "üìù [Gener√°lt]",
                    "outputs/PROJECT_ANALYSIS.md": "üìù [Gener√°lt]"
                }
            }
        else:
            # Hiba eset√©n
            errors = state["tool_errors"]
            last_error = errors[-1]["error"] if errors else "Ismeretlen hiba"
            status = {
                "current_task": "Automatikus projekt dokument√°ci√≥ gener√°l√°s (LangGraph verzi√≥)",
                "last_modification": f"Dokument√°ci√≥ gener√°l√°s sikertelen: {last_error}",
                "next_step": "A hiba jav√≠t√°sa √©s √∫jrapr√≥b√°lkoz√°s",
                "new_files": {
                    "auto_project_doc_langgraph.py": "üîÑ [Implement√°l√°s alatt]"
                }
            }
        
        # Friss√≠tj√ºk a st√°tusz f√°jlt
        await update_status(status_path, status)
        
        # Friss√≠tj√ºk az √°llapotot
        state["current_stage"] = "status_updated" if state["current_stage"] == "documentation_generated" else "error_reported"
        
        # Hozz√°adunk egy √ºzenetet a munkafolyamat napl√≥z√°s√°hoz
        add_messages(state, [
            {
                "role": "system",
                "content": f"PROJECT_STATUS.md friss√≠tve: {status['last_modification']}"
            }
        ])
    except Exception as e:
        error_msg = f"Hiba a PROJECT_STATUS.md friss√≠t√©se sor√°n: {str(e)}"
        logger.error(error_msg)
        state["tool_errors"].append({
            "stage": "update_project_status",
            "error": error_msg,
            "timestamp": datetime.now().isoformat()
        })
        state["current_stage"] = "error"
        add_messages(state, [
            {
                "role": "system",
                "content": error_msg
            }
        ])
    
    return state

# Munkafolyamat kond√≠ci√≥inak defin√≠ci√≥ja
def should_continue_on_error(state: DocGenState) -> str:
    """
    Eld√∂nti, hogy folytathat√≥-e a munkafolyamat hiba eset√©n.
    """
    if state["current_stage"] == "error":
        return "stop"
    return "continue"

def get_next_step(state: DocGenState) -> str:
    """
    Meghat√°rozza a k√∂vetkez≈ë l√©p√©st a munkafolyamatban.
    """
    current_stage = state["current_stage"]
    
    if current_stage == "project_structure_analyzed":
        return "analyze_files"
    elif current_stage == "files_analyzed":
        return "ai_analysis"
    elif current_stage == "ai_analysis_completed":
        return "generate_docs"
    elif current_stage == "documentation_generated":
        return "update_status"
    elif current_stage == "status_updated":
        # Ha befejezt√ºk a munk√°t, √∫jra kezdj√ºk a folyamatot (de ez nem fog futni, mert a main() f√ºggv√©ny kil√©p)
        return "analyze_project"
    else:
        # Alap√©rtelmezett √©rt√©k, csak hogy mindig legyen valid visszat√©r√©si √©rt√©k
        return "analyze_project"

# LangGraph munkafolyamat l√©trehoz√°sa
async def create_docgen_workflow(project_path: str) -> StateGraph:
    """
    L√©trehozza a dokument√°ci√≥ gener√°l√≥ LangGraph munkafolyamatot.
    """
    # Az eszk√∂z√∂k regisztr√°l√°sa
    await register_all_tools()
    
    # L√©trehozzuk a munkafolyamat gr√°fot
    workflow = StateGraph(DocGenState)
    
    # Csom√≥pontok hozz√°ad√°sa a munkafolyamathoz
    workflow.add_node("analyze_project", analyze_project_structure)
    workflow.add_node("analyze_files", analyze_python_files)
    workflow.add_node("ai_analysis", perform_ai_analysis)
    workflow.add_node("generate_docs", generate_documentation)
    workflow.add_node("update_status", update_project_status)
    
    # √âlek meghat√°roz√°sa a csom√≥pontok k√∂z√∂tt
    workflow.add_edge("analyze_project", "analyze_files")
    workflow.add_edge("analyze_files", "ai_analysis")
    workflow.add_edge("ai_analysis", "generate_docs")
    workflow.add_edge("generate_docs", "update_status")
      # Dinamikus el√°gaz√°sok kezel√©se
    workflow.add_conditional_edges(
        "update_status",
        get_next_step,
        {
            "update_status": "update_status",  # Ha m√©g nem fejez≈ëd√∂tt be
            "end": "analyze_project"  # Helyett egy l√©tez≈ë csom√≥pontot haszn√°lunk
        }
    )
      # Hibakezel√©s minden csom√≥pontban
    workflow.add_conditional_edges(
        "analyze_project",
        should_continue_on_error,
        {
            "continue": "analyze_files",
            "stop": "update_status"  # Hiba eset√©n friss√≠ts√ºk a st√°tuszt
        }
    )
    
    workflow.add_conditional_edges(
        "analyze_files",
        should_continue_on_error,
        {
            "continue": "ai_analysis",
            "stop": "update_status"  # Hiba eset√©n friss√≠ts√ºk a st√°tuszt
        }
    )
    
    workflow.add_conditional_edges(
        "ai_analysis",
        should_continue_on_error,
        {
            "continue": "generate_docs",
            "stop": "update_status"  # Hiba eset√©n friss√≠ts√ºk a st√°tuszt
        }
    )
    
    workflow.add_conditional_edges(
        "generate_docs",
        should_continue_on_error,
        {
            "continue": "update_status",
            "stop": "update_status"  # Hiba eset√©n is friss√≠ts√ºk a st√°tuszt
        }
    )
    
    # Defini√°ljuk a kezd≈ëcsom√≥pontot
    workflow.set_entry_point("analyze_project")
    
    return workflow

# F≈ë futtat√°si f√ºggv√©ny
async def main():
    """
    F≈ë bel√©p√©si pont a LangGraph alap√∫ dokument√°ci√≥ gener√°l√≥ futtat√°s√°hoz.
    """
    logger.info("=== Project-S Automatikus Dokument√°ci√≥ Gener√°l√≥ (LangGraph verzi√≥) ===")
    
    # Projekt k√∂nyvt√°r be√°ll√≠t√°sa
    project_path = str(Path(__file__).parent)
    
    try:
        # Friss√≠tj√ºk a PROJECT_STATUS.md-t az indul√°s jelz√©s√©re
        await update_status(
            os.path.join(project_path, "PROJECT_STATUS.md"),
            {
                "current_task": "Automatikus projekt dokument√°ci√≥ gener√°l√°s (LangGraph verzi√≥)",
                "last_modification": "Dokument√°ci√≥ gener√°l√≥ LangGraph workflow inicializ√°l√°sa",
                "next_step": "Workflow futtat√°sa √©s dokument√°ci√≥ gener√°l√°sa",
                "new_files": {
                    "auto_project_doc_langgraph.py": "‚úÖ [√öj]"
                }
            }
        )
        
        # Inicializ√°ljuk az √°llapotot
        state = init_docgen_state(project_path)
        
        # L√©trehozzuk a munkafolyamatot
        workflow = await create_docgen_workflow(project_path)
        
        # Egyszer≈±- nem LangGraph-kompatibilis - √°llapot haszn√°lata a tesztel√©shez
        simple_state = {
            "project_path": project_path,
            "output_dir": os.path.join(project_path, "outputs")
        }
        
        # K√∂zvetlen√ºl futtatjuk a funkci√≥kat tesztel√©s c√©lj√°b√≥l
        logger.info("üöÄ Munkafolyamat futtat√°sa k√∂zvetlen m√≥don (nem LangGraph-fal)...")
        
        # Projekt strukt√∫ra elemz√©se
        analyzer = ProjectStructureAnalyzer()
        project_data = await analyzer.get_project_structure(project_path)
        
        # Python f√°jlok r√©szletes elemz√©se
        file_analysis = await analyzer.analyze_python_files(project_data["python_files"])
        
        # AI elemz√©sek
        ai_integration = AIModelIntegration()
        context = {"project_data": project_data, "file_analysis": file_analysis}
        
        ai_results = {}
        
        # GPT-4 elemz√©s
        ai_results["architecture"] = await ai_integration.analyze_with_model(
            model="gpt-4", 
            prompt="Elemezd a projekt architekt√∫r√°j√°t √©s azonos√≠tsd a f≈ë design pattern-eket.",
            context=context
        )
        
        ai_results["code_structure"] = await ai_integration.analyze_with_model(
            model="gpt-4", 
            prompt="Elemezd a projekt k√≥d strukt√∫r√°j√°t √©s f≈ë komponenseit.",
            context=context
        )
        
        # Claude elemz√©s
        ai_results["best_practices"] = await ai_integration.analyze_with_model(
            model="claude-sonnet", 
            prompt="√ârt√©keld a k√≥d min≈ës√©g√©t √©s aj√°nlj best practices technik√°kat.",
            context=context
        )
        
        ai_results["security"] = await ai_integration.analyze_with_model(
            model="claude-sonnet", 
            prompt="√ârt√©keld a projekt biztons√°gi aspektusait.",
            context=context
        )
        
        # Dokument√°ci√≥ gener√°l√°sa
        doc_generator = DocumentationGenerator(os.path.join(project_path, "outputs"))
        readme_path = await doc_generator.generate_readme(project_data, ai_results)
        analysis_path = await doc_generator.generate_project_analysis(project_data, file_analysis, ai_results)
        
        # Friss√≠ts√ºk a PROJECT_STATUS.md-t a befejez√©s jelz√©s√©re
        await update_status(
            os.path.join(project_path, "PROJECT_STATUS.md"),
            {
                "current_task": "Automatikus projekt dokument√°ci√≥ gener√°l√°s (LangGraph verzi√≥)",
                "last_modification": "Dokument√°ci√≥ gener√°l√°s befejezve (k√∂zvetlen m√≥dban, LangGraph n√©lk√ºl)",
                "next_step": "A gener√°lt dokument√°ci√≥ ellen≈ërz√©se √©s LangGraph integr√°ci√≥ debuggol√°sa",
                "new_files": {
                    "auto_project_doc_langgraph.py": "üîÑ [Hibaelh√°r√≠t√°s alatt]",
                    "outputs/README.md": "üìù [Gener√°lt]",
                    "outputs/PROJECT_ANALYSIS.md": "üìù [Gener√°lt]"
                }
            }
        )
        
        logger.info("üéâ Dokument√°ci√≥ gener√°l√°s sikeres!")
        logger.info(f"üìÑ README.md: {readme_path}")
        logger.info(f"üìÑ PROJECT_ANALYSIS.md: {analysis_path}")
        
        return {
            "success": True,
            "readme_path": readme_path,
            "analysis_path": analysis_path,
            "note": "Futtatva k√∂zvetlen m√≥dban, nem LangGraph munkafolyamattal a kompatibilit√°si probl√©m√°k miatt."
        }
        
        # Megjegyz√©s: A LangGraph workflow futtat√°sa jelenleg deaktiv√°lva van kompatibilit√°si probl√©m√°k miatt
        # Az al√°bbi k√≥d vissza√°ll√≠that√≥, ha a LangGraph integr√°ci√≥ probl√©m√°i megold√≥dnak
        """
        # Konfigur√°lhat√≥ verzi√≥ban k√©sz√≠tj√ºk el a munkafolyamatot
        configurable_workflow = workflow.compile()
        
        # Futtatjuk a munkafolyamatot
        logger.info("üöÄ Munkafolyamat futtat√°sa...")
        final_state = await configurable_workflow.ainvoke(state)
        
        # Eredm√©ny feldolgoz√°sa
        current_stage = final_state["current_stage"]
        tool_errors = final_state["tool_errors"]
        
        if current_stage == "status_updated":
            logger.info("üéâ Dokument√°ci√≥ gener√°l√°s sikeres!")
            logger.info(f"üìÑ README.md: {final_state['output_paths']['readme_path']}")
            logger.info(f"üìÑ PROJECT_ANALYSIS.md: {final_state['output_paths']['analysis_path']}")
            return {
                "success": True,
                "readme_path": final_state['output_paths']['readme_path'],
                "analysis_path": final_state['output_paths']['analysis_path']
            }
        else:
            logger.error(f"üí• Dokument√°ci√≥ gener√°l√°s sikertelen: {current_stage}")
            for error in tool_errors:
                logger.error(f"- Hiba a '{error['stage']}' l√©p√©sn√©l: {error['error']}")
            return {
                "success": False,
                "error": tool_errors[-1]["error"] if tool_errors else "Ismeretlen hiba"
            }
        """
        
    except Exception as e:
        logger.error(f"Hiba a dokument√°ci√≥ gener√°l√≥ futtat√°sa k√∂zben: {str(e)}")
        traceback.print_exc()
        
        # Friss√≠tj√ºk a PROJECT_STATUS.md-t a hiba jelz√©s√©re
        await update_status(
            os.path.join(project_path, "PROJECT_STATUS.md"),
            {
                "current_task": "Automatikus projekt dokument√°ci√≥ gener√°l√°s",
                "last_modification": f"Hibaelh√°r√≠t√°s: {str(e)}",
                "next_step": "A hiba jav√≠t√°sa √©s √∫jrapr√≥b√°lkoz√°s"
            }
        )
        
        return {
            "success": False,
            "error": str(e)
        }

if __name__ == "__main__":
    result = asyncio.run(main())
    
    print("\n=== Automatikus Dokument√°ci√≥ Gener√°l√≥ (LangGraph) Eredm√©ny ===")
    if result.get("success", False):
        print("‚úÖ A dokument√°ci√≥ gener√°l√°s sikeresen befejezve!")
        print(f"üìä L√©trehozott f√°jlok:")
        print(f"  - {result.get('readme_path')}")
        print(f"  - {result.get('analysis_path')}")
    else:
        print(f"‚ùå Hiba: {result.get('error', 'Ismeretlen hiba')}")
